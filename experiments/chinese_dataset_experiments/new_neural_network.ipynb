{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6751e7-635f-490a-a5e1-800729e763cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.special import softmax as scipy_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1194fc38-c3fa-4a0e-a65b-14942de11f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed_data_course_based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d6934c-be6b-4b55-b14d-44e1324b26f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Number</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Grade 1 Rate</th>\n",
       "      <th>Grade 2 Rate</th>\n",
       "      <th>Grade 3 Rate</th>\n",
       "      <th>Grade 4 Rate</th>\n",
       "      <th>Grade 5 Rate</th>\n",
       "      <th>Mean Grade</th>\n",
       "      <th>STDEV Grade</th>\n",
       "      <th>Mean GPA</th>\n",
       "      <th>STDEV GPA</th>\n",
       "      <th>Department Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ideological and Moral Cultivation and Legal Fo...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.408377</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>3.547120</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Success: Career Planning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>0.298429</td>\n",
       "      <td>3.552356</td>\n",
       "      <td>1.025211</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Introduction to Computer Science</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>0.429319</td>\n",
       "      <td>0.096859</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.841040</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Advanced Mathematics A(1)</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>0.240838</td>\n",
       "      <td>0.217277</td>\n",
       "      <td>3.193717</td>\n",
       "      <td>1.359003</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>College English A(1)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>2.981675</td>\n",
       "      <td>0.843178</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>381</td>\n",
       "      <td>J2EE Framework</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>0.400524</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>3.510471</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>3.220775</td>\n",
       "      <td>0.515869</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>381</td>\n",
       "      <td>Intellectual Property and Software Protection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>0.366492</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>3.722513</td>\n",
       "      <td>1.007305</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>381</td>\n",
       "      <td>Human-Computer Interaction Technology</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060209</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>0.408377</td>\n",
       "      <td>0.117801</td>\n",
       "      <td>3.583770</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>381</td>\n",
       "      <td>Software Development and Testing Training</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.476440</td>\n",
       "      <td>0.463351</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>3.528796</td>\n",
       "      <td>0.608736</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>381</td>\n",
       "      <td>Python Language Programming</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>0.282723</td>\n",
       "      <td>0.235602</td>\n",
       "      <td>3.586387</td>\n",
       "      <td>1.025462</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student Number                                       Course Title  \\\n",
       "0                   0  Ideological and Moral Cultivation and Legal Fo...   \n",
       "1                   0                           Success: Career Planning   \n",
       "2                   0                   Introduction to Computer Science   \n",
       "3                   0                          Advanced Mathematics A(1)   \n",
       "4                   0                               College English A(1)   \n",
       "...               ...                                                ...   \n",
       "19095             381                                     J2EE Framework   \n",
       "19096             381      Intellectual Property and Software Protection   \n",
       "19097             381              Human-Computer Interaction Technology   \n",
       "19098             381          Software Development and Testing Training   \n",
       "19099             381                        Python Language Programming   \n",
       "\n",
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Grade 1 Rate  Grade 2 Rate  \\\n",
       "0          3.102564             19.5      0.000000      0.023560   \n",
       "1          3.102564             19.5      0.005236      0.086387   \n",
       "2          3.102564             19.5      0.007853      0.107330   \n",
       "3          3.102564             19.5      0.143979      0.193717   \n",
       "4          3.102564             19.5      0.028796      0.256545   \n",
       "...             ...              ...           ...           ...   \n",
       "19095      2.800000             20.0      0.007853      0.120419   \n",
       "19096      3.625000              8.0      0.000000      0.151832   \n",
       "19097      3.625000              8.0      0.000000      0.060209   \n",
       "19098      3.625000              8.0      0.000000      0.018325   \n",
       "19099      3.625000              8.0      0.000000      0.167539   \n",
       "\n",
       "       Grade 3 Rate  Grade 4 Rate  Grade 5 Rate  Mean Grade  STDEV Grade  \\\n",
       "0          0.486911      0.408377      0.081152    3.547120     0.677055   \n",
       "1          0.557592      0.052356      0.298429    3.552356     1.025211   \n",
       "2          0.358639      0.429319      0.096859    3.500000     0.841040   \n",
       "3          0.204188      0.240838      0.217277    3.193717     1.359003   \n",
       "4          0.439791      0.253927      0.020942    2.981675     0.843178   \n",
       "...             ...           ...           ...         ...          ...   \n",
       "19095      0.348168      0.400524      0.123037    3.510471     0.886555   \n",
       "19096      0.227749      0.366492      0.253927    3.722513     1.007305   \n",
       "19097      0.413613      0.408377      0.117801    3.583770     0.774968   \n",
       "19098      0.476440      0.463351      0.041885    3.528796     0.608736   \n",
       "19099      0.314136      0.282723      0.235602    3.586387     1.025462   \n",
       "\n",
       "       Mean GPA  STDEV GPA Department Code  \n",
       "0      3.307021   0.516455             BLG  \n",
       "1      3.307021   0.516455             BLG  \n",
       "2      3.307021   0.516455             BLG  \n",
       "3      3.307021   0.516455             BLG  \n",
       "4      3.307021   0.516455             BLG  \n",
       "...         ...        ...             ...  \n",
       "19095  3.220775   0.515869             BLG  \n",
       "19096  3.241516   0.494006             BLG  \n",
       "19097  3.241516   0.494006             BLG  \n",
       "19098  3.241516   0.494006             BLG  \n",
       "19099  3.241516   0.494006             BLG  \n",
       "\n",
       "[19100 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78198760-e40d-4695-88cb-130270cd2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([df.columns[0], df.columns[1]] ,inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f5003c-542c-4528-8793-08aaf8e74482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Grade 1 Rate</th>\n",
       "      <th>Grade 2 Rate</th>\n",
       "      <th>Grade 3 Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Grade 5 Rate</th>\n",
       "      <th>Mean Grade</th>\n",
       "      <th>STDEV Grade</th>\n",
       "      <th>Mean GPA</th>\n",
       "      <th>STDEV GPA</th>\n",
       "      <th>Department Code</th>\n",
       "      <th>Course Level</th>\n",
       "      <th>Status</th>\n",
       "      <th>Standing</th>\n",
       "      <th>Course Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>3.547120</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298429</td>\n",
       "      <td>3.552356</td>\n",
       "      <td>1.025211</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096859</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.841040</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Unsuccessful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217277</td>\n",
       "      <td>3.193717</td>\n",
       "      <td>1.359003</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>2.981675</td>\n",
       "      <td>0.843178</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>3.510471</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>3.220775</td>\n",
       "      <td>0.515869</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>3.722513</td>\n",
       "      <td>1.007305</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060209</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117801</td>\n",
       "      <td>3.583770</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.476440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>3.528796</td>\n",
       "      <td>0.608736</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235602</td>\n",
       "      <td>3.586387</td>\n",
       "      <td>1.025462</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Grade 1 Rate  Grade 2 Rate  \\\n",
       "0          3.102564             19.5      0.000000      0.023560   \n",
       "1          3.102564             19.5      0.005236      0.086387   \n",
       "2          3.102564             19.5      0.007853      0.107330   \n",
       "3          3.102564             19.5      0.143979      0.193717   \n",
       "4          3.102564             19.5      0.028796      0.256545   \n",
       "...             ...              ...           ...           ...   \n",
       "19095      2.800000             20.0      0.007853      0.120419   \n",
       "19096      3.625000              8.0      0.000000      0.151832   \n",
       "19097      3.625000              8.0      0.000000      0.060209   \n",
       "19098      3.625000              8.0      0.000000      0.018325   \n",
       "19099      3.625000              8.0      0.000000      0.167539   \n",
       "\n",
       "       Grade 3 Rate  ...  Grade 5 Rate  Mean Grade  STDEV Grade  Mean GPA  \\\n",
       "0          0.486911  ...      0.081152    3.547120     0.677055  3.307021   \n",
       "1          0.557592  ...      0.298429    3.552356     1.025211  3.307021   \n",
       "2          0.358639  ...      0.096859    3.500000     0.841040  3.307021   \n",
       "3          0.204188  ...      0.217277    3.193717     1.359003  3.307021   \n",
       "4          0.439791  ...      0.020942    2.981675     0.843178  3.307021   \n",
       "...             ...  ...           ...         ...          ...       ...   \n",
       "19095      0.348168  ...      0.123037    3.510471     0.886555  3.220775   \n",
       "19096      0.227749  ...      0.253927    3.722513     1.007305  3.241516   \n",
       "19097      0.413613  ...      0.117801    3.583770     0.774968  3.241516   \n",
       "19098      0.476440  ...      0.041885    3.528796     0.608736  3.241516   \n",
       "19099      0.314136  ...      0.235602    3.586387     1.025462  3.241516   \n",
       "\n",
       "       STDEV GPA  Department Code   Course Level        Status  Standing  \\\n",
       "0       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "1       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "2       0.516455              BLG  Undergraduate  Unsuccessful  Freshman   \n",
       "3       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "4       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "...          ...              ...            ...           ...       ...   \n",
       "19095   0.515869              BLG  Undergraduate    Successful    Junior   \n",
       "19096   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "19097   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "19098   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "19099   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "\n",
       "      Course Year  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "19095           3  \n",
       "19096           4  \n",
       "19097           4  \n",
       "19098           4  \n",
       "19099           4  \n",
       "\n",
       "[19100 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Course Level\"] = \"Undergraduate\"\n",
    "df['Status'] = np.where(df['Grades'] != 1, 'Successful', 'Unsuccessful')\n",
    "conditions = [\n",
    "    (df['Course Semester'] <= 2),\n",
    "    (df['Course Semester'] >= 3) & (df['Course Semester'] <= 4),\n",
    "    (df['Course Semester'] >= 5) & (df['Course Semester'] <= 6),\n",
    "    (df['Course Semester'] == 7)\n",
    "]\n",
    "\n",
    "choices = ['Freshman', 'Sophomore', 'Junior', 'Senior']\n",
    "\n",
    "# Create the new 'standing' column\n",
    "df['Standing'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "# Create Course Year column\n",
    "choices = [1, 2, 3, 4]\n",
    "\n",
    "df[\"Course Year\"] = np.select(conditions, choices, default=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced96182-47d8-4cd8-b8cd-4c11505741d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/1765600028.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df = pd.concat([df, pd.get_dummies(df['Course Year'], prefix='Course Year'), pd.get_dummies(df['Department Code'], prefix='Department Code'), pd.get_dummies(df['Course Level'], prefix='Course Level'), pd.get_dummies(df['Standing'], prefix='Standing'), pd.get_dummies(df['Status'], prefix='Status')], axis=1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Course Year'], prefix='Course Year'), pd.get_dummies(df['Department Code'], prefix='Department Code'), pd.get_dummies(df['Course Level'], prefix='Course Level'), pd.get_dummies(df['Standing'], prefix='Standing'), pd.get_dummies(df['Status'], prefix='Status')], axis=1)\n",
    "df.drop(['Course Year', 'Department Code', 'Course Level', 'Status', 'Standing'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc66edb-3103-4533-9a7a-1c0de6861892",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bbbba8-a7fc-4a63-96e5-bf70496af87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(['1', '2', '3', '4', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f194701e-0998-4d95-9cda-df488b3db8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_test):\n",
    "    X_train_cols = X_train.columns\n",
    "    X_test_cols = X_test.columns\n",
    "    sc = StandardScaler()\n",
    "    fitted_sc = sc.fit(X_train)\n",
    "    X_train_std = pd.DataFrame(fitted_sc.transform(X_train), columns=X_train_cols)\n",
    "    X_test_std = pd.DataFrame(fitted_sc.transform(X_test), columns=X_test_cols)\n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a3447a-266f-4812-8986-25ff0b76dc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Grade 1 Rate</th>\n",
       "      <th>Grade 2 Rate</th>\n",
       "      <th>Grade 3 Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Course Year_3</th>\n",
       "      <th>Course Year_4</th>\n",
       "      <th>Department Code_BLG</th>\n",
       "      <th>Course Level_Undergraduate</th>\n",
       "      <th>Standing_Freshman</th>\n",
       "      <th>Standing_Junior</th>\n",
       "      <th>Standing_Senior</th>\n",
       "      <th>Standing_Sophomore</th>\n",
       "      <th>Status_Successful</th>\n",
       "      <th>Status_Unsuccessful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060209</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.476440</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Grade 1 Rate  Grade 2 Rate  \\\n",
       "0          3.102564             19.5      0.000000      0.023560   \n",
       "1          3.102564             19.5      0.005236      0.086387   \n",
       "2          3.102564             19.5      0.007853      0.107330   \n",
       "3          3.102564             19.5      0.143979      0.193717   \n",
       "4          3.102564             19.5      0.028796      0.256545   \n",
       "...             ...              ...           ...           ...   \n",
       "19095      2.800000             20.0      0.007853      0.120419   \n",
       "19096      3.625000              8.0      0.000000      0.151832   \n",
       "19097      3.625000              8.0      0.000000      0.060209   \n",
       "19098      3.625000              8.0      0.000000      0.018325   \n",
       "19099      3.625000              8.0      0.000000      0.167539   \n",
       "\n",
       "       Grade 3 Rate  ...  Course Year_3  Course Year_4  Department Code_BLG  \\\n",
       "0          0.486911  ...              0              0                    1   \n",
       "1          0.557592  ...              0              0                    1   \n",
       "2          0.358639  ...              0              0                    1   \n",
       "3          0.204188  ...              0              0                    1   \n",
       "4          0.439791  ...              0              0                    1   \n",
       "...             ...  ...            ...            ...                  ...   \n",
       "19095      0.348168  ...              1              0                    1   \n",
       "19096      0.227749  ...              0              1                    1   \n",
       "19097      0.413613  ...              0              1                    1   \n",
       "19098      0.476440  ...              0              1                    1   \n",
       "19099      0.314136  ...              0              1                    1   \n",
       "\n",
       "       Course Level_Undergraduate  Standing_Freshman  Standing_Junior  \\\n",
       "0                               1                  1                0   \n",
       "1                               1                  1                0   \n",
       "2                               1                  1                0   \n",
       "3                               1                  1                0   \n",
       "4                               1                  1                0   \n",
       "...                           ...                ...              ...   \n",
       "19095                           1                  0                1   \n",
       "19096                           1                  0                0   \n",
       "19097                           1                  0                0   \n",
       "19098                           1                  0                0   \n",
       "19099                           1                  0                0   \n",
       "\n",
       "       Standing_Senior  Standing_Sophomore  Status_Successful  \\\n",
       "0                    0                   0                  1   \n",
       "1                    0                   0                  1   \n",
       "2                    0                   0                  0   \n",
       "3                    0                   0                  1   \n",
       "4                    0                   0                  1   \n",
       "...                ...                 ...                ...   \n",
       "19095                0                   0                  1   \n",
       "19096                1                   0                  1   \n",
       "19097                1                   0                  1   \n",
       "19098                1                   0                  1   \n",
       "19099                1                   0                  1   \n",
       "\n",
       "       Status_Unsuccessful  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "19095                    0  \n",
       "19096                    0  \n",
       "19097                    0  \n",
       "19098                    0  \n",
       "19099                    0  \n",
       "\n",
       "[19100 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68801176-e094-45b1-a6f0-0fd7521c76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(df, train_sem, columns):\n",
    "    dataFrame = pd.DataFrame(columns=columns)\n",
    "    for sem in train_sem:\n",
    "        dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
    "    \n",
    "    X_train = dataFrame.drop('Course Semester', axis=1)\n",
    "    y_train = le.transform(X_train.pop('Grades'))\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208b643d-236e-4987-9f9d-a136a71a0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_structure(X, Y):\n",
    "    input_unit = X.shape[0] # size of input layer\n",
    "    hidden_unit = X.shape[0] # hidden layer of size 4\n",
    "    output_unit = Y.shape[0] # size of output layer\n",
    "    return (input_unit, hidden_unit, output_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf7512b-8c79-4394-901b-f6f2c4283a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_initialization(input_unit, hidden_unit, output_unit):\n",
    "    np.random.seed(41)\n",
    "    W1 = np.random.randn(hidden_unit, input_unit) * 0.01\n",
    "    b1 = np.zeros((hidden_unit, 1))\n",
    "    W2 = np.random.randn(output_unit, hidden_unit) * 0.01\n",
    "    b2 = np.zeros((output_unit, 1))\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fc76a4-3cba-461c-83e7-dd38a70d4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return scipy_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dadad9d4-2b48-4db9-8f28-e145838545e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6c71c9a-dbfb-4e12-9edf-641667650b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_cost(A2, Y, parameters):\n",
    "    #number of training example\n",
    "    m = Y.shape[1]\n",
    "    logprobs = np.multiply(np.log(A2), Y)\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = float(np.squeeze(cost))\n",
    "                                    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0ef13d-9ad5-40a5-a67a-43a1e263cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    #number of training example\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "   \n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T) \n",
    "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2,\"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56cc7417-f5bc-4c8c-9b17-2425189a05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(parameters, grads, learning_rate = 0.01):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "   \n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1, \"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b312db42-b191-4144-b723-7e8d8e56c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(X, Y, hidden_unit, num_iterations = 98):\n",
    "    np.random.seed(3)\n",
    "    input_unit = define_structure(X, Y)[0]\n",
    "    output_unit = define_structure(X, Y)[2]\n",
    "    \n",
    "    parameters = parameters_initialization(input_unit, hidden_unit, output_unit)\n",
    "   \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = entropy_cost(A2, Y, parameters)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = gradient_descent(parameters, grads)\n",
    "        if i % 5 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17597e76-96c4-481e-b348-49226206d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.round(A2)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d42fd09-05c7-4838-873a-4d47f256d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_score(df, columns):\n",
    "    error_scores = {}\n",
    "    sorted_semesters = sorted(set(df.iloc[:, 2]))\n",
    "    for sem_idx in range(1, len(sorted_semesters)):\n",
    "        training_sem = sorted_semesters[:sem_idx]\n",
    "        test_sem = sorted_semesters[sem_idx]\n",
    "        X_train, y_train = get_train_data(df, training_sem, columns)\n",
    "        X_test = df[df.iloc[:, 2] == test_sem]\n",
    "        X_test.drop('Course Semester', axis=1, inplace=True)\n",
    "        y_test = le.transform(X_test.pop('Grades'))\n",
    "        \n",
    "        X_train, X_test = standardize(X_train, X_test)\n",
    "        \n",
    "        X_train = X_train.T.to_numpy()   # (number of attributes, number of samples)\n",
    "        y_train = y_train.reshape(1, y_train.shape[0])   # (1, number of samples)\n",
    "        \n",
    "        X_test = X_test.T.to_numpy()   # (number of attributes, number of samples)\n",
    "        y_test = y_test.reshape(1, y_test.shape[0])   # (1, number of samples)\n",
    "        \n",
    "        parameters = neural_network_model(X_train, y_train, 58, num_iterations=490)\n",
    "        \n",
    "        y_pred_test = prediction(parameters, X_test)\n",
    "        rmse_test = round(np.sqrt(mean_squared_error(y_test[0], y_pred_test[0])), 3)\n",
    "        mae_test = round(mean_absolute_error(y_test[0], y_pred_test[0]), 3)\n",
    "        \n",
    "        y_pred_train = prediction(parameters, X_train)\n",
    "        rmse_train = round(np.sqrt(mean_squared_error(y_train[0], y_pred_train[0])), 3)\n",
    "        mae_train = round(mean_absolute_error(y_train[0], y_pred_train[0]),3)\n",
    "        \n",
    "        error_scores.setdefault(sem_idx, {})\n",
    "        error_scores[sem_idx]['rmse'] = [rmse_train, rmse_test]\n",
    "        error_scores[sem_idx]['mae'] = [mae_train, mae_test]        \n",
    "        \n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3071f7fb-2119-441e-b0e3-1194ccd11655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb14eeb2-b37d-4e37-8156-e189e9773854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 18.911436\n",
      "Cost after iteration 5: 18.911047\n",
      "Cost after iteration 10: 18.910634\n",
      "Cost after iteration 15: 18.910182\n",
      "Cost after iteration 20: 18.909672\n",
      "Cost after iteration 25: 18.909084\n",
      "Cost after iteration 30: 18.908395\n",
      "Cost after iteration 35: 18.907577\n",
      "Cost after iteration 40: 18.906597\n",
      "Cost after iteration 45: 18.905415\n",
      "Cost after iteration 50: 18.903984\n",
      "Cost after iteration 55: 18.902248\n",
      "Cost after iteration 60: 18.900141\n",
      "Cost after iteration 65: 18.897588\n",
      "Cost after iteration 70: 18.894509\n",
      "Cost after iteration 75: 18.890817\n",
      "Cost after iteration 80: 18.886438\n",
      "Cost after iteration 85: 18.881316\n",
      "Cost after iteration 90: 18.875451\n",
      "Cost after iteration 95: 18.868936\n",
      "Cost after iteration 100: 18.862028\n",
      "Cost after iteration 105: 18.855240\n",
      "Cost after iteration 110: 18.849470\n",
      "Cost after iteration 115: 18.846173\n",
      "Cost after iteration 120: 18.847557\n",
      "Cost after iteration 125: 18.856825\n",
      "Cost after iteration 130: 18.878407\n",
      "Cost after iteration 135: 18.918182\n",
      "Cost after iteration 140: 18.983597\n",
      "Cost after iteration 145: 19.083561\n",
      "Cost after iteration 150: 19.227970\n",
      "Cost after iteration 155: 19.426706\n",
      "Cost after iteration 160: 19.688183\n",
      "Cost after iteration 165: 20.017707\n",
      "Cost after iteration 170: 20.416112\n",
      "Cost after iteration 175: 20.879020\n",
      "Cost after iteration 180: 21.396856\n",
      "Cost after iteration 185: 21.955496\n",
      "Cost after iteration 190: 22.537325\n",
      "Cost after iteration 195: 23.122514\n",
      "Cost after iteration 200: 23.690425\n",
      "Cost after iteration 205: 24.221053\n",
      "Cost after iteration 210: 24.696421\n",
      "Cost after iteration 215: 25.101766\n",
      "Cost after iteration 220: 25.426368\n",
      "Cost after iteration 225: 25.663902\n",
      "Cost after iteration 230: 25.812334\n",
      "Cost after iteration 235: 25.873478\n",
      "Cost after iteration 240: 25.852385\n",
      "Cost after iteration 245: 25.756704\n",
      "Cost after iteration 250: 25.596091\n",
      "Cost after iteration 255: 25.381634\n",
      "Cost after iteration 260: 25.125242\n",
      "Cost after iteration 265: 24.838975\n",
      "Cost after iteration 270: 24.534330\n",
      "Cost after iteration 275: 24.221590\n",
      "Cost after iteration 280: 23.909305\n",
      "Cost after iteration 285: 23.604010\n",
      "Cost after iteration 290: 23.310184\n",
      "Cost after iteration 295: 23.030437\n",
      "Cost after iteration 300: 22.765860\n",
      "Cost after iteration 305: 22.516448\n",
      "Cost after iteration 310: 22.281540\n",
      "Cost after iteration 315: 22.060188\n",
      "Cost after iteration 320: 21.851441\n",
      "Cost after iteration 325: 21.654511\n",
      "Cost after iteration 330: 21.468837\n",
      "Cost after iteration 335: 21.294072\n",
      "Cost after iteration 340: 21.130012\n",
      "Cost after iteration 345: 20.976509\n",
      "Cost after iteration 350: 20.833396\n",
      "Cost after iteration 355: 20.700427\n",
      "Cost after iteration 360: 20.577256\n",
      "Cost after iteration 365: 20.463440\n",
      "Cost after iteration 370: 20.358452\n",
      "Cost after iteration 375: 20.261713\n",
      "Cost after iteration 380: 20.172619\n",
      "Cost after iteration 385: 20.090562\n",
      "Cost after iteration 390: 20.014951\n",
      "Cost after iteration 395: 19.945227\n",
      "Cost after iteration 400: 19.880864\n",
      "Cost after iteration 405: 19.821379\n",
      "Cost after iteration 410: 19.766330\n",
      "Cost after iteration 415: 19.715315\n",
      "Cost after iteration 420: 19.667972\n",
      "Cost after iteration 425: 19.623974\n",
      "Cost after iteration 430: 19.583025\n",
      "Cost after iteration 435: 19.544862\n",
      "Cost after iteration 440: 19.509245\n",
      "Cost after iteration 445: 19.475960\n",
      "Cost after iteration 450: 19.444813\n",
      "Cost after iteration 455: 19.415632\n",
      "Cost after iteration 460: 19.388257\n",
      "Cost after iteration 465: 19.362549\n",
      "Cost after iteration 470: 19.338376\n",
      "Cost after iteration 475: 19.315624\n",
      "Cost after iteration 480: 19.294185\n",
      "Cost after iteration 485: 19.273964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/3765939947.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  logprobs = np.multiply(np.log(A2), Y)\n",
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/3765939947.py:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  logprobs = np.multiply(np.log(A2), Y)\n",
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 19.788679\n",
      "Cost after iteration 5: 19.788071\n",
      "Cost after iteration 10: 19.787433\n",
      "Cost after iteration 15: 19.786736\n",
      "Cost after iteration 20: 19.785950\n",
      "Cost after iteration 25: 19.785043\n",
      "Cost after iteration 30: 19.783975\n",
      "Cost after iteration 35: 19.782699\n",
      "Cost after iteration 40: 19.781160\n",
      "Cost after iteration 45: 19.779293\n",
      "Cost after iteration 50: 19.777019\n",
      "Cost after iteration 55: 19.774248\n",
      "Cost after iteration 60: 19.770874\n",
      "Cost after iteration 65: 19.766782\n",
      "Cost after iteration 70: 19.761852\n",
      "Cost after iteration 75: 19.755974\n",
      "Cost after iteration 80: 19.749066\n",
      "Cost after iteration 85: 19.741119\n",
      "Cost after iteration 90: 19.732258\n",
      "Cost after iteration 95: 19.722839\n",
      "Cost after iteration 100: 19.713586\n",
      "Cost after iteration 105: 19.705784\n",
      "Cost after iteration 110: 19.701532\n",
      "Cost after iteration 115: 19.704032\n",
      "Cost after iteration 120: 19.717921\n",
      "Cost after iteration 125: 19.749557\n",
      "Cost after iteration 130: 19.807207\n",
      "Cost after iteration 135: 19.901000\n",
      "Cost after iteration 140: 20.042497\n",
      "Cost after iteration 145: 20.243767\n",
      "Cost after iteration 150: 20.515953\n",
      "Cost after iteration 155: 20.867540\n",
      "Cost after iteration 160: 21.302728\n",
      "Cost after iteration 165: 21.820337\n",
      "Cost after iteration 170: 22.413465\n",
      "Cost after iteration 175: 23.069890\n",
      "Cost after iteration 180: 23.773003\n",
      "Cost after iteration 185: 24.503070\n",
      "Cost after iteration 190: 25.238630\n",
      "Cost after iteration 195: 25.957891\n",
      "Cost after iteration 200: 26.640032\n",
      "Cost after iteration 205: 27.266330\n",
      "Cost after iteration 210: 27.821054\n",
      "Cost after iteration 215: 28.292103\n",
      "Cost after iteration 220: 28.671335\n",
      "Cost after iteration 225: 28.954619\n",
      "Cost after iteration 230: 29.141611\n",
      "Cost after iteration 235: 29.235336\n",
      "Cost after iteration 240: 29.241654\n",
      "Cost after iteration 245: 29.168634\n",
      "Cost after iteration 250: 29.025904\n",
      "Cost after iteration 255: 28.823964\n",
      "Cost after iteration 260: 28.573525\n",
      "Cost after iteration 265: 28.284941\n",
      "Cost after iteration 270: 27.967768\n",
      "Cost after iteration 275: 27.630508\n",
      "Cost after iteration 280: 27.280511\n",
      "Cost after iteration 285: 26.923990\n",
      "Cost after iteration 290: 26.566123\n",
      "Cost after iteration 295: 26.211184\n",
      "Cost after iteration 300: 25.862686\n",
      "Cost after iteration 305: 25.523483\n",
      "Cost after iteration 310: 25.195837\n",
      "Cost after iteration 315: 24.881440\n",
      "Cost after iteration 320: 24.581433\n",
      "Cost after iteration 325: 24.296440\n",
      "Cost after iteration 330: 24.026647\n",
      "Cost after iteration 335: 23.771924\n",
      "Cost after iteration 340: 23.531961\n",
      "Cost after iteration 345: 23.306397\n",
      "Cost after iteration 350: 23.094894\n",
      "Cost after iteration 355: 22.897162\n",
      "Cost after iteration 360: 22.712941\n",
      "Cost after iteration 365: 22.541958\n",
      "Cost after iteration 370: 22.383883\n",
      "Cost after iteration 375: 22.238294\n",
      "Cost after iteration 380: 22.104656\n",
      "Cost after iteration 385: 21.982306\n",
      "Cost after iteration 390: 21.870450\n",
      "Cost after iteration 395: 21.768158\n",
      "Cost after iteration 400: 21.674379\n",
      "Cost after iteration 405: 21.587960\n",
      "Cost after iteration 410: 21.507693\n",
      "Cost after iteration 415: 21.432370\n",
      "Cost after iteration 420: 21.360869\n",
      "Cost after iteration 425: 21.292230\n",
      "Cost after iteration 430: 21.225730\n",
      "Cost after iteration 435: 21.160918\n",
      "Cost after iteration 440: 21.097610\n",
      "Cost after iteration 445: 21.035837\n",
      "Cost after iteration 450: 20.975772\n",
      "Cost after iteration 455: 20.917647\n",
      "Cost after iteration 460: 20.861692\n",
      "Cost after iteration 465: 20.808090\n",
      "Cost after iteration 470: 20.756961\n",
      "Cost after iteration 475: 20.708359\n",
      "Cost after iteration 480: 20.662280\n",
      "Cost after iteration 485: 20.618675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 19.560010\n",
      "Cost after iteration 5: 19.559120\n",
      "Cost after iteration 10: 19.558178\n",
      "Cost after iteration 15: 19.557144\n",
      "Cost after iteration 20: 19.555972\n",
      "Cost after iteration 25: 19.554611\n",
      "Cost after iteration 30: 19.553002\n",
      "Cost after iteration 35: 19.551076\n",
      "Cost after iteration 40: 19.548752\n",
      "Cost after iteration 45: 19.545936\n",
      "Cost after iteration 50: 19.542521\n",
      "Cost after iteration 55: 19.538386\n",
      "Cost after iteration 60: 19.533407\n",
      "Cost after iteration 65: 19.527461\n",
      "Cost after iteration 70: 19.520456\n",
      "Cost after iteration 75: 19.512364\n",
      "Cost after iteration 80: 19.503286\n",
      "Cost after iteration 85: 19.493548\n",
      "Cost after iteration 90: 19.483848\n",
      "Cost after iteration 95: 19.475457\n",
      "Cost after iteration 100: 19.470490\n",
      "Cost after iteration 105: 19.472226\n",
      "Cost after iteration 110: 19.485451\n",
      "Cost after iteration 115: 19.516737\n",
      "Cost after iteration 120: 19.574537\n",
      "Cost after iteration 125: 19.668967\n",
      "Cost after iteration 130: 19.811152\n",
      "Cost after iteration 135: 20.012165\n",
      "Cost after iteration 140: 20.281733\n",
      "Cost after iteration 145: 20.626977\n",
      "Cost after iteration 150: 21.051488\n",
      "Cost after iteration 155: 21.554826\n",
      "Cost after iteration 160: 22.132417\n",
      "Cost after iteration 165: 22.775728\n",
      "Cost after iteration 170: 23.472636\n",
      "Cost after iteration 175: 24.207985\n",
      "Cost after iteration 180: 24.964337\n",
      "Cost after iteration 185: 25.722899\n",
      "Cost after iteration 190: 26.464502\n",
      "Cost after iteration 195: 27.170574\n",
      "Cost after iteration 200: 27.824007\n",
      "Cost after iteration 205: 28.409949\n",
      "Cost after iteration 210: 28.916514\n",
      "Cost after iteration 215: 29.335386\n",
      "Cost after iteration 220: 29.662183\n",
      "Cost after iteration 225: 29.896442\n",
      "Cost after iteration 230: 30.041156\n",
      "Cost after iteration 235: 30.101967\n",
      "Cost after iteration 240: 30.086249\n",
      "Cost after iteration 245: 30.002311\n",
      "Cost after iteration 250: 29.858815\n",
      "Cost after iteration 255: 29.664397\n",
      "Cost after iteration 260: 29.427409\n",
      "Cost after iteration 265: 29.155760\n",
      "Cost after iteration 270: 28.856821\n",
      "Cost after iteration 275: 28.537383\n",
      "Cost after iteration 280: 28.203611\n",
      "Cost after iteration 285: 27.860973\n",
      "Cost after iteration 290: 27.514174\n",
      "Cost after iteration 295: 27.167128\n",
      "Cost after iteration 300: 26.823019\n",
      "Cost after iteration 305: 26.484422\n",
      "Cost after iteration 310: 26.153464\n",
      "Cost after iteration 315: 25.831938\n",
      "Cost after iteration 320: 25.521365\n",
      "Cost after iteration 325: 25.222980\n",
      "Cost after iteration 330: 24.937704\n",
      "Cost after iteration 335: 24.666113\n",
      "Cost after iteration 340: 24.408453\n",
      "Cost after iteration 345: 24.164678\n",
      "Cost after iteration 350: 23.934515\n",
      "Cost after iteration 355: 23.717541\n",
      "Cost after iteration 360: 23.513248\n",
      "Cost after iteration 365: 23.321088\n",
      "Cost after iteration 370: 23.140483\n",
      "Cost after iteration 375: 22.970813\n",
      "Cost after iteration 380: 22.811391\n",
      "Cost after iteration 385: 22.661449\n",
      "Cost after iteration 390: 22.520139\n",
      "Cost after iteration 395: 22.386559\n",
      "Cost after iteration 400: 22.259795\n",
      "Cost after iteration 405: 22.138984\n",
      "Cost after iteration 410: 22.023368\n",
      "Cost after iteration 415: 21.912347\n",
      "Cost after iteration 420: 21.805493\n",
      "Cost after iteration 425: 21.702535\n",
      "Cost after iteration 430: 21.603323\n",
      "Cost after iteration 435: 21.507790\n",
      "Cost after iteration 440: 21.415921\n",
      "Cost after iteration 445: 21.327730\n",
      "Cost after iteration 450: 21.243243\n",
      "Cost after iteration 455: 21.162482\n",
      "Cost after iteration 460: 21.085449\n",
      "Cost after iteration 465: 21.012121\n",
      "Cost after iteration 470: 20.942442\n",
      "Cost after iteration 475: 20.876325\n",
      "Cost after iteration 480: 20.813653\n",
      "Cost after iteration 485: 20.754291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 20.520748\n",
      "Cost after iteration 5: 20.519934\n",
      "Cost after iteration 10: 20.519072\n",
      "Cost after iteration 15: 20.518123\n",
      "Cost after iteration 20: 20.517047\n",
      "Cost after iteration 25: 20.515796\n",
      "Cost after iteration 30: 20.514314\n",
      "Cost after iteration 35: 20.512537\n",
      "Cost after iteration 40: 20.510386\n",
      "Cost after iteration 45: 20.507769\n",
      "Cost after iteration 50: 20.504577\n",
      "Cost after iteration 55: 20.500682\n",
      "Cost after iteration 60: 20.495943\n",
      "Cost after iteration 65: 20.490204\n",
      "Cost after iteration 70: 20.483312\n",
      "Cost after iteration 75: 20.475134\n",
      "Cost after iteration 80: 20.465598\n",
      "Cost after iteration 85: 20.454760\n",
      "Cost after iteration 90: 20.442895\n",
      "Cost after iteration 95: 20.430655\n",
      "Cost after iteration 100: 20.419268\n",
      "Cost after iteration 105: 20.410814\n",
      "Cost after iteration 110: 20.408560\n",
      "Cost after iteration 115: 20.417319\n",
      "Cost after iteration 120: 20.443789\n",
      "Cost after iteration 125: 20.496756\n",
      "Cost after iteration 130: 20.587047\n",
      "Cost after iteration 135: 20.727080\n",
      "Cost after iteration 140: 20.929894\n",
      "Cost after iteration 145: 21.207665\n",
      "Cost after iteration 150: 21.569922\n",
      "Cost after iteration 155: 22.021860\n",
      "Cost after iteration 160: 22.563247\n",
      "Cost after iteration 165: 23.188145\n",
      "Cost after iteration 170: 23.885387\n",
      "Cost after iteration 175: 24.639558\n",
      "Cost after iteration 180: 25.432205\n",
      "Cost after iteration 185: 26.243087\n",
      "Cost after iteration 190: 27.051383\n",
      "Cost after iteration 195: 27.836780\n",
      "Cost after iteration 200: 28.580418\n",
      "Cost after iteration 205: 29.265662\n",
      "Cost after iteration 210: 29.878676\n",
      "Cost after iteration 215: 30.408793\n",
      "Cost after iteration 220: 30.848691\n",
      "Cost after iteration 225: 31.194387\n",
      "Cost after iteration 230: 31.445069\n",
      "Cost after iteration 235: 31.602782\n",
      "Cost after iteration 240: 31.672002\n",
      "Cost after iteration 245: 31.659102\n",
      "Cost after iteration 250: 31.571768\n",
      "Cost after iteration 255: 31.418418\n",
      "Cost after iteration 260: 31.207685\n",
      "Cost after iteration 265: 30.948020\n",
      "Cost after iteration 270: 30.647431\n",
      "Cost after iteration 275: 30.313365\n",
      "Cost after iteration 280: 29.952690\n",
      "Cost after iteration 285: 29.571744\n",
      "Cost after iteration 290: 29.176395\n",
      "Cost after iteration 295: 28.772086\n",
      "Cost after iteration 300: 28.363838\n",
      "Cost after iteration 305: 27.956231\n",
      "Cost after iteration 310: 27.553362\n",
      "Cost after iteration 315: 27.158808\n",
      "Cost after iteration 320: 26.775609\n",
      "Cost after iteration 325: 26.406257\n",
      "Cost after iteration 330: 26.052700\n",
      "Cost after iteration 335: 25.716356\n",
      "Cost after iteration 340: 25.398136\n",
      "Cost after iteration 345: 25.098483\n",
      "Cost after iteration 350: 24.817426\n",
      "Cost after iteration 355: 24.554649\n",
      "Cost after iteration 360: 24.309563\n",
      "Cost after iteration 365: 24.081378\n",
      "Cost after iteration 370: 23.869178\n",
      "Cost after iteration 375: 23.671968\n",
      "Cost after iteration 380: 23.488729\n",
      "Cost after iteration 385: 23.318448\n",
      "Cost after iteration 390: 23.160142\n",
      "Cost after iteration 395: 23.012877\n",
      "Cost after iteration 400: 22.875775\n",
      "Cost after iteration 405: 22.748016\n",
      "Cost after iteration 410: 22.628847\n",
      "Cost after iteration 415: 22.517571\n",
      "Cost after iteration 420: 22.413553\n",
      "Cost after iteration 425: 22.316212\n",
      "Cost after iteration 430: 22.225018\n",
      "Cost after iteration 435: 22.139487\n",
      "Cost after iteration 440: 22.059180\n",
      "Cost after iteration 445: 21.983696\n",
      "Cost after iteration 450: 21.912671\n",
      "Cost after iteration 455: 21.845771\n",
      "Cost after iteration 460: 21.782694\n",
      "Cost after iteration 465: 21.723162\n",
      "Cost after iteration 470: 21.666922\n",
      "Cost after iteration 475: 21.613744\n",
      "Cost after iteration 480: 21.563414\n",
      "Cost after iteration 485: 21.515739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 21.385400\n",
      "Cost after iteration 5: 21.384537\n",
      "Cost after iteration 10: 21.383620\n",
      "Cost after iteration 15: 21.382606\n",
      "Cost after iteration 20: 21.381450\n",
      "Cost after iteration 25: 21.380098\n",
      "Cost after iteration 30: 21.378487\n",
      "Cost after iteration 35: 21.376543\n",
      "Cost after iteration 40: 21.374178\n",
      "Cost after iteration 45: 21.371286\n",
      "Cost after iteration 50: 21.367743\n",
      "Cost after iteration 55: 21.363405\n",
      "Cost after iteration 60: 21.358114\n",
      "Cost after iteration 65: 21.351703\n",
      "Cost after iteration 70: 21.344015\n",
      "Cost after iteration 75: 21.334937\n",
      "Cost after iteration 80: 21.324459\n",
      "Cost after iteration 85: 21.312762\n",
      "Cost after iteration 90: 21.300371\n",
      "Cost after iteration 95: 21.288358\n",
      "Cost after iteration 100: 21.278635\n",
      "Cost after iteration 105: 21.274328\n",
      "Cost after iteration 110: 21.280205\n",
      "Cost after iteration 115: 21.303109\n",
      "Cost after iteration 120: 21.352282\n",
      "Cost after iteration 125: 21.439422\n",
      "Cost after iteration 130: 21.578288\n",
      "Cost after iteration 135: 21.783708\n",
      "Cost after iteration 140: 22.069963\n",
      "Cost after iteration 145: 22.448755\n",
      "Cost after iteration 150: 22.927174\n",
      "Cost after iteration 155: 23.506171\n",
      "Cost after iteration 160: 24.179885\n",
      "Cost after iteration 165: 24.935906\n",
      "Cost after iteration 170: 25.756323\n",
      "Cost after iteration 175: 26.619262\n",
      "Cost after iteration 180: 27.500634\n",
      "Cost after iteration 185: 28.375824\n",
      "Cost after iteration 190: 29.221172\n",
      "Cost after iteration 195: 30.015146\n",
      "Cost after iteration 200: 30.739178\n",
      "Cost after iteration 205: 31.378169\n",
      "Cost after iteration 210: 31.920699\n",
      "Cost after iteration 215: 32.359027\n",
      "Cost after iteration 220: 32.688951\n",
      "Cost after iteration 225: 32.909579\n",
      "Cost after iteration 230: 33.023031\n",
      "Cost after iteration 235: 33.034079\n",
      "Cost after iteration 240: 32.949760\n",
      "Cost after iteration 245: 32.778986\n",
      "Cost after iteration 250: 32.532189\n",
      "Cost after iteration 255: 32.220969\n",
      "Cost after iteration 260: 31.857717\n",
      "Cost after iteration 265: 31.455149\n",
      "Cost after iteration 270: 31.025752\n",
      "Cost after iteration 275: 30.581188\n",
      "Cost after iteration 280: 30.131741\n",
      "Cost after iteration 285: 29.685911\n",
      "Cost after iteration 290: 29.250209\n",
      "Cost after iteration 295: 28.829187\n",
      "Cost after iteration 300: 28.425665\n",
      "Cost after iteration 305: 28.041094\n",
      "Cost after iteration 310: 27.675964\n",
      "Cost after iteration 315: 27.330187\n",
      "Cost after iteration 320: 27.003380\n",
      "Cost after iteration 325: 26.695030\n",
      "Cost after iteration 330: 26.404546\n",
      "Cost after iteration 335: 26.131244\n",
      "Cost after iteration 340: 25.874299\n",
      "Cost after iteration 345: 25.632724\n",
      "Cost after iteration 350: 25.405388\n",
      "Cost after iteration 355: 25.191072\n",
      "Cost after iteration 360: 24.988566\n",
      "Cost after iteration 365: 24.796769\n",
      "Cost after iteration 370: 24.614764\n",
      "Cost after iteration 375: 24.441860\n",
      "Cost after iteration 380: 24.277577\n",
      "Cost after iteration 385: 24.121606\n",
      "Cost after iteration 390: 23.973740\n",
      "Cost after iteration 395: 23.833810\n",
      "Cost after iteration 400: 23.701647\n",
      "Cost after iteration 405: 23.577042\n",
      "Cost after iteration 410: 23.459744\n",
      "Cost after iteration 415: 23.349458\n",
      "Cost after iteration 420: 23.245850\n",
      "Cost after iteration 425: 23.148566\n",
      "Cost after iteration 430: 23.057234\n",
      "Cost after iteration 435: 22.971483\n",
      "Cost after iteration 440: 22.890946\n",
      "Cost after iteration 445: 22.815267\n",
      "Cost after iteration 450: 22.744110\n",
      "Cost after iteration 455: 22.677154\n",
      "Cost after iteration 460: 22.614101\n",
      "Cost after iteration 465: 22.554673\n",
      "Cost after iteration 470: 22.498611\n",
      "Cost after iteration 475: 22.445677\n",
      "Cost after iteration 480: 22.395652\n",
      "Cost after iteration 485: 22.348334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s7/jgc_z9fj1tq65hb0wg4tr7lm0000gn/T/ipykernel_40797/393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 22.158871\n",
      "Cost after iteration 5: 22.158076\n",
      "Cost after iteration 10: 22.157231\n",
      "Cost after iteration 15: 22.156298\n",
      "Cost after iteration 20: 22.155234\n",
      "Cost after iteration 25: 22.153991\n",
      "Cost after iteration 30: 22.152513\n",
      "Cost after iteration 35: 22.150732\n",
      "Cost after iteration 40: 22.148568\n",
      "Cost after iteration 45: 22.145926\n",
      "Cost after iteration 50: 22.142697\n",
      "Cost after iteration 55: 22.138752\n",
      "Cost after iteration 60: 22.133955\n",
      "Cost after iteration 65: 22.128162\n",
      "Cost after iteration 70: 22.121246\n",
      "Cost after iteration 75: 22.113130\n",
      "Cost after iteration 80: 22.103842\n",
      "Cost after iteration 85: 22.093608\n",
      "Cost after iteration 90: 22.082994\n",
      "Cost after iteration 95: 22.073111\n",
      "Cost after iteration 100: 22.065890\n",
      "Cost after iteration 105: 22.064440\n",
      "Cost after iteration 110: 22.073444\n",
      "Cost after iteration 115: 22.099548\n",
      "Cost after iteration 120: 22.151624\n",
      "Cost after iteration 125: 22.240756\n",
      "Cost after iteration 130: 22.379801\n",
      "Cost after iteration 135: 22.582420\n",
      "Cost after iteration 140: 22.861641\n",
      "Cost after iteration 145: 23.228164\n",
      "Cost after iteration 150: 23.688764\n",
      "Cost after iteration 155: 24.245093\n",
      "Cost after iteration 160: 24.893060\n",
      "Cost after iteration 165: 25.622799\n",
      "Cost after iteration 170: 26.419171\n",
      "Cost after iteration 175: 27.262714\n",
      "Cost after iteration 180: 28.130920\n",
      "Cost after iteration 185: 28.999665\n",
      "Cost after iteration 190: 29.844669\n",
      "Cost after iteration 195: 30.642840\n",
      "Cost after iteration 200: 31.373405\n",
      "Cost after iteration 205: 32.018776\n",
      "Cost after iteration 210: 32.565099\n",
      "Cost after iteration 215: 33.002568\n",
      "Cost after iteration 220: 33.325508\n",
      "Cost after iteration 225: 33.532275\n",
      "Cost after iteration 230: 33.624974\n",
      "Cost after iteration 235: 33.609011\n",
      "Cost after iteration 240: 33.492542\n",
      "Cost after iteration 245: 33.285927\n",
      "Cost after iteration 250: 33.001202\n",
      "Cost after iteration 255: 32.651590\n",
      "Cost after iteration 260: 32.250969\n",
      "Cost after iteration 265: 31.813265\n",
      "Cost after iteration 270: 31.351807\n",
      "Cost after iteration 275: 30.878730\n",
      "Cost after iteration 280: 30.404537\n",
      "Cost after iteration 285: 29.937869\n",
      "Cost after iteration 290: 29.485479\n",
      "Cost after iteration 295: 29.052350\n",
      "Cost after iteration 300: 28.641895\n",
      "Cost after iteration 305: 28.256173\n",
      "Cost after iteration 310: 27.896099\n",
      "Cost after iteration 315: 27.561633\n",
      "Cost after iteration 320: 27.251966\n",
      "Cost after iteration 325: 26.965703\n",
      "Cost after iteration 330: 26.701046\n",
      "Cost after iteration 335: 26.455973\n",
      "Cost after iteration 340: 26.228400\n",
      "Cost after iteration 345: 26.016300\n",
      "Cost after iteration 350: 25.817776\n",
      "Cost after iteration 355: 25.631105\n",
      "Cost after iteration 360: 25.454750\n",
      "Cost after iteration 365: 25.287391\n",
      "Cost after iteration 370: 25.127953\n",
      "Cost after iteration 375: 24.975631\n",
      "Cost after iteration 380: 24.829896\n",
      "Cost after iteration 385: 24.690459\n",
      "Cost after iteration 390: 24.557211\n",
      "Cost after iteration 395: 24.430145\n",
      "Cost after iteration 400: 24.309286\n",
      "Cost after iteration 405: 24.194638\n",
      "Cost after iteration 410: 24.086158\n",
      "Cost after iteration 415: 23.983740\n",
      "Cost after iteration 420: 23.887221\n",
      "Cost after iteration 425: 23.796384\n",
      "Cost after iteration 430: 23.710973\n",
      "Cost after iteration 435: 23.630707\n",
      "Cost after iteration 440: 23.555290\n",
      "Cost after iteration 445: 23.484422\n",
      "Cost after iteration 450: 23.417806\n",
      "Cost after iteration 455: 23.355156\n",
      "Cost after iteration 460: 23.296197\n",
      "Cost after iteration 465: 23.240670\n",
      "Cost after iteration 470: 23.188332\n",
      "Cost after iteration 475: 23.138959\n",
      "Cost after iteration 480: 23.092341\n",
      "Cost after iteration 485: 23.048284\n"
     ]
    }
   ],
   "source": [
    "scores = get_error_score(df, columns)\n",
    "model_results['NN'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45f75009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted average RMSE: 2.4958333333333336\n",
      "Weighted average MAE: 2.282238095238095\n"
     ]
    }
   ],
   "source": [
    "weights = [9, 8, 7, 6, 8, 4]\n",
    "total_weight = sum(weights)\n",
    "\n",
    "# Weighted average RMSE\n",
    "weighted_sum_rmse = 0\n",
    "for i, key in enumerate(model_results['NN'], start=0):\n",
    "    rmse_value = model_results['NN'][key]['rmse'][1]\n",
    "    weighted_sum_rmse += weights[i] * rmse_value\n",
    "\n",
    "weighted_avg_rmse = weighted_sum_rmse / total_weight\n",
    "print(\"Weighted average RMSE:\", weighted_avg_rmse)\n",
    "\n",
    "# Weighted average MAE\n",
    "weighted_sum_mae = 0\n",
    "for i, key in enumerate(model_results['NN'], start=0):\n",
    "    mae_value = model_results['NN'][key]['mae'][1]\n",
    "    weighted_sum_mae += weights[i] * mae_value\n",
    "\n",
    "weighted_avg_mae = weighted_sum_mae / total_weight\n",
    "print(\"Weighted average MAE:\", weighted_avg_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c7a937a-9502-4332-a1f9-30ad7ba414d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Your results\n",
    "results = {\n",
    "    \"chinese_nn\": {\n",
    "        \"WeightedAvgRMSE\": 2.4958333333333336,\n",
    "        \"WeightedAvgMAE\": 2.282238095238095\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"chinese_nn.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9aba7-21d0-4c6e-b587-c57ce0faa28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a6b4a203dba8dbd3b51a1f65dce59b4625dd99cdb36f1505991052a59cd223b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
